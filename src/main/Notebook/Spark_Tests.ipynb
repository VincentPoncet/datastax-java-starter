{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "case class OrderLine (\n",
    "    sku : String,\n",
    "    productName : String,\n",
    "    thumbnailImage: String,\n",
    "    quantity : Double,\n",
    "    unitPrice : Double,\n",
    "    totalPrice : Double\n",
    ")\n",
    "\n",
    "case class Order (\n",
    "    customerId : java.util.UUID ,\n",
    "    orderId : java.util.UUID ,\n",
    "    date : java.util.Date ,\n",
    "    OrderLines_ : List[OrderLine] ,\n",
    "    totalPrice : Double\n",
    ")\n",
    "\n",
    "case class RecommendedProduct (\n",
    "    sku : String,\n",
    "    product_name : String,\n",
    "    regular_price : Double,\n",
    "    thumbnail_image : String\n",
    ");\n",
    "\n",
    "case class ProductRecommendations (\n",
    "    sku : String,\n",
    "    product_name : String,\n",
    "    recommended_products : List[RecommendedProduct]\n",
    ");\n",
    "\n",
    "case class Top50SellingProducts (\n",
    "    sku : String,\n",
    "    productName : String,\n",
    "    saleCount : Double,\n",
    "    saleValue : Double,\n",
    "    thumbnailImage : String\n",
    ");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val orders = sc.cassandraTable[Order](\"retail_ks\",\"orders\").persist(org.apache.spark.storage.StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Long = 1000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val orderlines = orders.flatMap ( order => order.OrderLines_).map( ol => (ol.sku, (ol.productName, ol.thumbnailImage, ol.quantity, ol. unitPrice, ol.totalPrice)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orderlines.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val soldproducts = orderlines.reduceByKey( (a,b) => (a._1, a._2, a._3+b._3, a._4, a._5+b._5)).\n",
    "    map( { case ( sku, (productName, thumbnailImage, count, unitPrice, value) ) => Top50SellingProducts (sku, productName, count, value, thumbnailImage) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val Top50CountSellingProducts = soldproducts.sortBy(  -_.saleValue  ).\n",
    "    zipWithIndex.\n",
    "    filter{case (_, idx) => idx < 50}.\n",
    "    keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Top50CountSellingProducts.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Top50CountSellingProducts.saveToCassandra(\"retail_ks\",\"top50_selling_products\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val ProductCoOccurance = orders.\n",
    "    flatMap( order => order.OrderLines_.\n",
    "        map(  ol => ( ol.sku , order.OrderLines_.\n",
    "            map(ol => (ol.sku, (ol.productName, ol.thumbnailImage, ol.quantity, ol. unitPrice, ol.totalPrice))).filter ( ol3 => ol3._1!=`ol`.sku)\n",
    "                ) // for each order, make a list of product cooccurance (product1, product2)\n",
    "            )\n",
    "            ).reduceByKey{ (a,b) =>\n",
    "                           // for each product1, merge list on key product2\n",
    "                          val groupedBySku = (a++b).groupBy( { case (sku,(pn, ti, q, up, tp)) => sku } ).values.toList\n",
    "                          // aggregate value sum of product2\n",
    "                          groupedBySku.map( listOfProduct => listOfProduct.reduce( (a,b) => (a._1, (a._2._1, a._2._2, a._2._3+b._2._3, a._2._4, a._2._5+b._2._5))) )\n",
    "\n",
    "                           }. // merge the list per product1\n",
    "                mapValues { TotalSumBySku =>\n",
    "                // for each product1, merge list on key product2\n",
    "               // val groupedBySku = x.groupBy( { case (sku,(pn, ti, q, up, tp)) => sku } ).values.toList\n",
    "               // aggregate value sum of product2\n",
    "               // val TotalSumBySku = groupedBySku.map( listOfProduct => listOfProduct.reduce( (a,b) => (a._1, (a._2._1, a._2._2, a._2._3+b._2._3, a._2._4, a._2._5+b._2._5))) )\n",
    "               // take top50 product2 sorted on summed value\n",
    "               val Top50Value = TotalSumBySku.sortBy(-_._2._5).slice(0,50)\n",
    "               // create a RecommendedProduct item to fit table structure\n",
    "               Top50Value.map( lop => RecommendedProduct(lop._1, lop._2._1, lop._2._4  , lop._2._2  ))\n",
    "                        }.\n",
    "            // create a ProductRecommendation to fit table structure\n",
    "            map( pco => ProductRecommendations(pco._1, \"\", pco._2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val sqlContext = new org.apache.spark.sql.hive.HiveContext(sc)\n",
    "import sqlContext.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sku: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- recommended_products: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- sku: string (nullable = true)\n",
      " |    |    |-- product_name: string (nullable = true)\n",
      " |    |    |-- regular_price: double (nullable = false)\n",
      " |    |    |-- thumbnail_image: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val pcodf = ProductCoOccurance.toDF\n",
    "pcodf.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcodf.write.format(\"org.apache.spark.sql.cassandra\").\n",
    "    options(Map( \"table\" -> \"product_recommendations\", \"keyspace\" -> \"retail_ks\")).\n",
    "    mode(\"overwrite\").\n",
    "    save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ProductCoOccurance.collect.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ProductCoOccurance.saveToCassandra(\"retail_ks\",\"product_recommendations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.cassandraTable[productRecommendations](\"retail_ks\",\"product_recommendations\").collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val pcodf_read = sqlContext.read.format(\"org.apache.spark.sql.cassandra\").\n",
    "\toptions(Map( \"table\" -> \"product_recommendations\", \"keyspace\" -> \"retail_ks\")).\n",
    "\tload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcodf_read.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ProductCoOccurance.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ProductCoOccurance.take(1).foreach(println(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ProductCoOccurance.map(_.recommended_products.size).collect.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark-DSE Cluster (Scala 2.10.4)",
   "language": "scala",
   "name": "spark-dse-cluster"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
